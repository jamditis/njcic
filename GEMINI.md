# NJCIC Research & Dashboard Project Context

## Project Overview
This project is a dual-component system designed to track and visualize the impact of the **New Jersey Civic Information Consortium (NJCIC)** grantees. It consists of a Python-based social media scraper infrastructure and a static web dashboard for visualizing the collected metrics.

### Key Components

1.  **`njcic-scraper/` (Backend/Data Collection)**
    *   A robust Python framework for extracting social media URLs and scraping engagement metrics (posts, likes, shares) from grantee websites.
    *   **Supported Platforms:** Facebook, Instagram, Twitter/X, YouTube, TikTok, LinkedIn, Bluesky, Threads.
    *   **Tech Stack:** Python 3.9+, Playwright (browser automation), `yt-dlp`, `instaloader`, `tweepy`, `pandas`.

2.  **`dashboard/` (Frontend/Visualization)**
    *   A static HTML/CSS/JS web application that consumes the scraped JSON data.
    *   **Features:** Interactive charts (Chart.js), grantee rankings, platform analytics, and individual grantee profiles.
    *   **Tech Stack:** Vanilla JavaScript (ES6+), Chart.js, Tailwind CSS (via classes, likely pre-built or CDN), HTML5.

3.  **Automation (`.github/workflows/`)**
    *   The `update-dashboard.yml` workflow automates the weekly data refresh.
    *   **Flow:** Extract URLs -> Scrape Data -> Validate -> Update `dashboard-data.json` -> Commit changes.

## Directory Structure

*   **`njcic-scraper/`**
    *   `scrapers/`: Individual platform scraper modules inheriting from `base.py`.
    *   `scripts/`: Utilities for URL extraction (`extract_social_urls.py`), data preparation (`prepare_dashboard_data.py`), and validation.
    *   `output/` & `data/`: Storage for intermediate and final JSON datasets.
    *   `config.py`: Central configuration (timeouts, rate limits).
*   **`dashboard/`**
    *   `data/`: Contains `dashboard-data.json` (the app's database).
    *   `js/`: `app.js` (core logic), `charts.js` (visualization), `rankings.js`.
    *   `grantees/`: Generated HTML pages for individual grantees.
*   **`research/`**: Documentation and analysis of the NJCIC ecosystem.

## Development & Usage

### 1. Python Scraper Setup
**Prerequisites:** Python 3.9+, Chrome/Chromium (for Playwright).

```bash
cd njcic-scraper

# Create and activate virtual environment
python3 -m venv venv
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
playwright install chromium

# Configuration
# Copy .env.example to .env and populate API keys (Twitter, YouTube, etc.)
cp .env.example .env
```

**Common Commands:**

*   **Extract URLs from Grantee Sites:**
    ```bash
    python scripts/extract_social_urls.py
    ```
*   **Run Scraper (Main Entry):**
    ```bash
    # Scrape specific platforms
    python main.py --platforms twitter,youtube,bluesky
    ```

### 2. Dashboard Setup
Since the dashboard is a static site, it requires no build step.

*   **Run Locally:**
    ```bash
    cd dashboard
    python3 -m http.server 8000
    # Visit http://localhost:8000
    ```
*   **Data Refresh:** The dashboard reads from `dashboard/data/dashboard-data.json`. This file is generated by the scraper's `scripts/prepare_dashboard_data.py` script.

## Automation & Deployment
The project uses **GitHub Actions** (`update-dashboard.yml`) to keep data fresh.
*   **Schedule:** Mondays at 12:00 UTC.
*   **Process:**
    1.  Sets up Python & Playwright.
    2.  Runs `extract_social_urls.py`.
    3.  Runs the main scraper.
    4.  Runs `prepare_dashboard_data.py`.
    5.  Commits the updated JSON files back to the repository.

## Coding Conventions
*   **Python:** Follows PEP 8. Uses `pydantic` for validation and type hinting where possible. Scrapers are class-based inheriting from `BaseScraper`.
*   **JavaScript:** Vanilla ES6+. strict mode enabled (`'use strict';`). Modularized logic (e.g., `app.js` for main controller, `charts.js` for rendering).
*   **Data:** JSON is the primary interchange format. Keys are typically camelCase in JS and snake_case in Python, with normalization steps in the JS frontend.
